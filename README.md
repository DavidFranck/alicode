# 项目介绍
alibaba interview

## 题目1
- 编写2个用户之间的转账接口及其内部实现
- 要求：完成接口设计、并实现其内部逻辑，以完成A用户转账给B用户的功能。2个用户的账户不在同一个数据库下。注意需要手写代码，尽量不要用伪代码。
- 提示：接口发布后会暴露给外部应用进行服务调用，请考虑接口规范、安全、幂等、重试、并发、有可能的异常分支、事务一致性、用户投诉、资金安全等的处理。

### 答
1. 定义ResResult,使用ResponseEntity<Result> 统一返回结构 接口使REST规范 
2. 使用validator  @Valid + 实体类注解 进行参数校验 保证安全性
3. 保证转账接口的幂等性,同一个交易号只能进行一次转账操作,如果已存在，则将存在的转账信息返回
4. 转账过程（A账户向B账户转账）需要在一个事务里,避免造成死锁,将系统中的账户排序,账户id小的先执行
5. 为了保证在并发情况下,同一时刻只允许一个线程操作转账过程中涉及到的账户,但是其他账户可以被其他线程操作，
   因此选择数据的行锁（Mysql InnoDB行锁 for update实现） 转账放在同一个事务中 失败的话两个sql同事回滚保持一致性
6. 用spring aop 切入需要打印日志的方法搜集日志便于查找问题

## 题目2
- 用户在支付宝钱包里面给好友发送群红包，试设计群红包涉及的各接口及其内部实现
- 要求：需要做类图,序列图,边界设计、并注意做好并发控制，接口实现需完整。用户领取红包金额随机，但需要保障每个用户至少领到1分钱。红包包好之后，通知用户来领取，如果过期时间之内没领完，需要被回收。注意需要手写代码，尽量不要用伪码。
- 提示：可打开支付宝钱包尝试用一次看下页面交互，部分涉及外部调用的地方可进行mock或者伪码来完成。
### 答
1. 设计了 发送红包,抢红包,退款的接口。
2. 发红包: 扣除账号金额 生成红包金额 存储在mysql 红包金额使用List存储在redis中 
3. 抢红包: 利用的是 Redis 的原子性 使用 Redis 的 lpop list中的金额 加到自己账号余额中
4. 退款: 启动定时任务 超时而且没有领取完成 剩余金额退还给原账户 
3. 使用策略模式 切换红包金额生成策略

## 题目3
- 计算某一账户的余额日变动信息，给出简短的代码逻辑实现
### 答
```
    //期初借方余额
    Double beforeDebitBalance = 0D;
    //期初贷方余额
    Double beforeCreditBalance = 100D;
    System.out.println("期初借方余额:" + beforeDebitBalance);
    System.out.println("期初贷方余额:" + beforeCreditBalance);
    //借方发生额 为借方金额相加
    Double debitAmount = 100D;
    //贷方发生额 为贷方金额相加
    Double creditAmount = 50D;
    System.out.println("贷方发生额:" + creditAmount);
    System.out.println("借方发生额:" + debitAmount);
    //期末借方余额 为借方余额加+借方发生额
    Double afterDebitBalance = beforeDebitBalance + debitAmount;
    //期末贷方余额 为贷方余额+贷方发生额
    Double afterCreditBalance = beforeCreditBalance + creditAmount;
    System.out.println("期末借方余额:" + afterDebitBalance);
    System.out.println("期末贷方余额:" + afterCreditBalance);

```

## 题目4
- 给出网络重试场景下的一致性解决方案
- 两台应用服务器，一台数据库服务器的环境下面，一笔支付交易，因为网络重试原因，导致支付请求重复发送，如何解决这一场景下幂等性问题，请给出解决方案。
### 答
1. 交易会生成唯一的交易id,服务端使用redis存储交易id(key)交易信息(value)
2. 重试时当库里存在该交易id 并且为支付中状态 则继续支付,为其它状态直接返回前端。不存在则创建该交易。

## 题目5
- 给定两个文件，分别有100亿个整数，只提供1G内存，如何找出两文件交集？
- 提示：100亿个整数大约需要40G才能存下，一次性读入到内存中是不现实的，可考虑MapReduce实现。
### 答
1. 如果可以允许有误差 并且要求效率的话 可以使用BloomFilter 遍历把其中一个文件读进BloomFilter,再遍历另一个文件 把存在的数字写到结果文件中
2. 切分成200个小文件 遍历文件 a 每一行的数字hash(n)%200 把一个大文件中切分到不同partition中(相同的数字肯定在相同partition中)。文件b同样处理各个 partition中 分别内存计算200对文件相同的数字 然后把结果合并到一个文件中

